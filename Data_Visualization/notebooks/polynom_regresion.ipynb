{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive plot\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib as mpl\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Warnungen vom Typ DeprecationWarning ignorieren\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import os\n",
    "\n",
    "y_column_name = \"Total\"\n",
    "\n",
    "data = pd.read_excel(\n",
    "    \"Daten\\Endenergieverbrauch_nach_Energietr채ger.xlsx\",\n",
    "    sheet_name=\"Tabelle1\",\n",
    "    usecols=[\n",
    "        \"Jahr\",\n",
    "        \"Brennstoffe\",\n",
    "        \"Treibstoffe\",\n",
    "        \"Elektrizit채t\",\n",
    "        \"Gas\",\n",
    "        \"Kohle\",\n",
    "        \"Holz und Holzkohle\",\n",
    "        \"체brige Energietr채ger\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# df_enver.set_index('Jahr', inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data[\"Total\"] = data.sum(axis=1)\n",
    "\n",
    "# data['Jahr'] = pd.to_datetime(data['Jahr']).dt.year\n",
    "\n",
    "\n",
    "def train_test_split_time_series(data, test_size):\n",
    "    \"\"\"\n",
    "    Split time series data into training and testing sets while preserving temporal order.\n",
    "\n",
    "    Parameters:\n",
    "    data (list or numpy array): Time series data.\n",
    "    test_size (float): Proportion of data to include in the test set (0 < test_size < 1).\n",
    "\n",
    "    Returns:\n",
    "    train_data (list or numpy array): Training data.\n",
    "    test_data (list or numpy array): Testing data.\n",
    "    \"\"\"\n",
    "    if not 0 < test_size < 1:\n",
    "        raise ValueError(\"test_size should be a float between 0 and 1\")\n",
    "\n",
    "    split_index = int(len(data) * (1 - test_size))\n",
    "    train_data, test_data = data[:split_index], data[split_index:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "train, test = train_test_split_time_series(data, 0.2)\n",
    "train, verification = train_test_split_time_series(train, 0.2)\n",
    "\n",
    "\n",
    "y_train = train[y_column_name]\n",
    "y_verification = verification[y_column_name]\n",
    "y_test = test[y_column_name]\n",
    "\n",
    "x_train = train[\"Jahr\"]\n",
    "x_verification = verification[\"Jahr\"]\n",
    "x_test = test[\"Jahr\"]\n",
    "\n",
    "# Reshape the input data\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "x_verification = x_verification.values.reshape(-1, 1)\n",
    "x_test = x_test.values.reshape(-1, 1)\n",
    "\n",
    "# Apply the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_verification = scaler.transform(x_verification)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "# Convert back to DataFrame if needed\n",
    "x_train = pd.DataFrame(x_train, columns=[\"Jahr\"])\n",
    "x_verification = pd.DataFrame(x_verification, columns=[\"Jahr\"])\n",
    "x_test = pd.DataFrame(x_test, columns=[\"Jahr\"])\n",
    "\n",
    "x_columns = x_train.values\n",
    "\n",
    "data.set_index(\"Jahr\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "class PolynomialLinearRegression:\n",
    "    def __init__(self, x_train, y_train, x_verification, y_verification, degrees):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_verification = x_verification\n",
    "        self.y_verification = y_verification\n",
    "        self.degrees = degrees\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        best_degree = None\n",
    "        best_score = -1\n",
    "\n",
    "        for degree in self.degrees:\n",
    "            # print(f\"Trying model with degree {degree}\")\n",
    "            poly = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "\n",
    "            x_train_poly = poly.fit_transform(self.x_train)\n",
    "            x_verification_poly = poly.transform(self.x_verification)\n",
    "\n",
    "            self.model.fit(x_train_poly, self.y_train)\n",
    "            y_pred = self.model.predict(x_verification_poly)\n",
    "\n",
    "            r2 = r2_score(self.y_verification, y_pred)\n",
    "\n",
    "            if r2 > best_score:\n",
    "                best_score = r2\n",
    "                best_degree = degree\n",
    "\n",
    "            directory = f\"./PolynomialLinearRegression{degree}\"\n",
    "            self.clean_output(directory)\n",
    "            self.evaluate(directory, y_pred)\n",
    "            self.plot_results(\n",
    "                directory, degree, x_train_poly, x_verification_poly, y_pred\n",
    "            )\n",
    "\n",
    "        return best_degree, best_score\n",
    "\n",
    "    def evaluate(self, folder, y_pred):\n",
    "        with open(f\"{folder}/metric.txt\", \"w\") as f:\n",
    "            f.write(f\"R2: {r2_score(self.y_verification, y_pred)} \\n\")\n",
    "            f.write(\n",
    "                f\"MAPE: {mean_absolute_percentage_error(self.y_verification, y_pred)}\"\n",
    "            )\n",
    "\n",
    "    def clean_output(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        else:\n",
    "            for filename in os.listdir(folder):\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                try:\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting file: {file_path} - {e}\")\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        poly = PolynomialFeatures(degree=self.best_degree, include_bias=True)\n",
    "        x_new_poly = poly.fit_transform(x_new)\n",
    "        y_pred = self.model.predict(x_new_poly)\n",
    "        return y_pred\n",
    "\n",
    "    def plot_results(self, folder, degree, x_train_poly, x_verification_poly, y_pred):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot training data in blue\n",
    "        plt.scatter(self.x_train, self.y_train, color=\"blue\", label=\"Train Data\")\n",
    "\n",
    "        # Plot test/verification data in black\n",
    "        plt.scatter(\n",
    "            self.x_verification,\n",
    "            self.y_verification,\n",
    "            color=\"black\",\n",
    "            label=\"Test/Verification Data\",\n",
    "        )\n",
    "\n",
    "        # Sort the data points for the predicted curve\n",
    "        sorted_indices = np.argsort(x_verification_poly[:, 1])\n",
    "\n",
    "        # Plot the predicted data in red\n",
    "        plt.plot(\n",
    "            x_verification_poly[sorted_indices, 1],\n",
    "            y_pred[sorted_indices],\n",
    "            color=\"red\",\n",
    "            label=\"Predicted Data\",\n",
    "        )\n",
    "\n",
    "        # Calculate and display the R2 Score\n",
    "        r2 = r2_score(self.y_verification, y_pred)\n",
    "\n",
    "        # Calculate and display the MAPE\n",
    "        mape = mean_absolute_percentage_error(self.y_verification, y_pred)\n",
    "        plt.text(\n",
    "            0.7,\n",
    "            0.25,\n",
    "            f\"R2 Score: {r2:.2f}\\nMAPE: {mape:.2f}\",\n",
    "            fontsize=12,\n",
    "            transform=plt.gca().transAxes,\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Polynomial Linear Regression (Degree {degree})\")\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.savefig(f\"{folder}/plot.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Beispielverwendung der Klasse:\n",
    "degrees_to_try = range(1, 6)\n",
    "poly_reg = PolynomialLinearRegression(\n",
    "    x_train, y_train, x_verification, y_verification, degrees_to_try\n",
    ")\n",
    "best_degree, best_score = poly_reg.train_and_evaluate()\n",
    "# print(f\"Best Degree: {best_degree}\")\n",
    "# print(f\"Best R2 Score: {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
